dasm kernel.asm -lkernel.txt -f3 -v5 -okernel.bin

0. Rip frames out to individual images

Use ffmpeg, -t 30 is to limit to 30 seconds of output, -r 1 can make 1 frame/sec,
bmp is just random uncompressed format.

ffmpeg -i sintel-1024-stereo.ogv -s 160x192 -pix_fmt abgr -f image2 frame-%7d.tiff


1. Use ImageMagick to quantize the individual frames using the color reference image.

convert frame-00297.tiff +dither -remap refcolors_ntsc.tiff remap-frame-00297.tiff

it seems to be adding a color profile, which we might want to remove with +profile *

can experiment with other dithering algorithms, e.g. -dither FloydSteinberg, or if the
dithering is adding too much noise consider +dither to disable.

Dithering makes individual images look good, but adds too much noise for a movie.

TODO: paralellize. Currently hella slow.

NOTE: to go back to a test mp4

ffmpeg -pix_fmt abgr -s 160x192 -f image2 -i frame-%7d.tiff -r 24 original.mp4

Kernel Designs:

76 machine cycles per scanline. 228 color clocks consisting of 68 horizontal
blank, 160 color.
that means that 22 1/3 clock counts in hblank, 53 2/3 clock counts in color.
use color clocks as timing in a scanline, since it goes from 0-227.

an LDA immediate is 2 clocks. A STA zero-page is 3, absolute is 4. So minimum 5
clocks to update something, possibly 6. Meaning 4-5 updates in hblank at most,
10 during drawing. tight tight! looks like TIA is mostly in the zero-page.
transfer between registers is quite fast, 1 clock. TXA and friends.
for loading and storing x,a, and y are equal in speed.

max 4 colors per line? not so! because you can change the colors at any time.
it just costs you :).

2-pass compiler. first pass is what needs to be set to what, and when, for line
to render. minimize TIA state change, and include an entry set of conditions,
calculate an exit set of conditions.
second pass considers whole image timeframe, including vblank, and tries to make
everything fit in, using 3 registers, the six or so zero-page RAM locations, and
other memory locations as available.

first pass, heuristic approach:

identify best bg and pf candidates. both bg and pf are drawn in 4-pixel blocks.
pf has weird symmetry opportunities - either being repeated or mirrored, so
look for that. tie breakers are based on current TIA state - re-use BG color?
re-use parts of PF bitfield? etc.

players draw in 8 pixels, so slightly faster than 3 clock cycles.


state block: basically everything in the TIA.
***************

Frame is one whole frame of animation. It takes an Image* as input (non-owning).
Produces Image* at end, along with assembly language or even bytecode that
generates that image.

Frame consists of a series of Commands, which are fed into a Scheduler, which
can reject them based on availability of resources.

Command is something like "set background color register to $00." Commands have
deadlines, absolute times by which they must be done. They might also have
dependencies between each other, or be aware somehow of blackouts.

Using the player sprite at time t. We've determined that turning on the player
sprite with bitfield 0xaf and color 0xcc, horizontal offset at 0x01, player
doubling disabled. Those are the preconditions and they have a deadline. Going
back from that deadline, then, the question is what is the earliest time each
of those could be met? There's also a strobe command to fire the player which
has very tight timing constraints and must be issued on a certain cycle.

Some talk about graceful degredation - best perhaps to handle it as just other
sets of commands. They have different preconditions, the scheduler may be able
to take advantage of prior state.

Commands should try to generate their optimum strategy, but some commands don't
have to - like "just strobe the player 1" - perhaps we can't schedule a command
to change the bitfield in the player1 position at this time, but strobing it
results in lower error than not..

Start with just setting background color. Then add playfield options.

======

HARD SCHEDULING:

76 machine cycles per scanline sort of limits the options. Additionally,
some strategies really limit availability of other options.
5 clocks per LDA/STA pair, 2 for the LDA Immediate mode, 3 for STA zero-page.
22 clocks in hblank, so 4 load/store pairs, and 54 in scanout.

Start of Scan Line:

a) Strobe HMOVE or HCLR - 3 clocks.
b) Update PF0           - 5 clocks.
e) Update 1 color       - 5 clocks.
c) Update GP0           - 5 clocks.
d) Update GP1           - 5 clocks.

There's about 25 things we chould change in this time, (25 choose 5) = 53510.

BG color fitter - majority color on any given line. costs 5 clocks (unless BG unchanged).
PF fitter - second majority color. set color before scanout costs 5 clocks (unless unchanged).
  then another 5 clocks for PF0 during hblank, then another 5 for pf1, and other 5
  for pf2, then pf0 again, then pf1, then pf2. So potentially 30 for bitfields and 5 for
  color, 10 of it during hblank.


================================================================================

Constraints. How to represent what must be done and when. Some examples:

a) playfield fitter wants to change PF1 to 0xef for this and the next scanline.
this means there's a deadline for PF1 which is the color clock when the first pf1
bit is scanned out to the screen. The range in which it could be set is anytime
before that, up until the last blackout of pf1. The blackout on pf1 is then for
the color clocks until pf1 has scanned out a second time. The PF color should not
change during this time. Smaller state changes seem better, so consider only one
 - like during this time of pf1 being scanned out, pf1 bitfield is off limits,
  and it needs to be 0xef for this time.
pf color seems dangerous to paint outside of hblank, as does bg color. so each
line will first decide on pf and bg colors. - during scanout, bg color needs to
be x, pf color needs to be y.

anyway, constraint is like pf1 needs to be 0xef from t_0 to t_1, and also
colupf needs to be 0xaa from t_0 to t_1 too. So that's two contraints, which
can be modeled as two time ranges on those two registers.


================================================================================

What would a playfield-only kernel look like?

PF0 in use from color clock 68 up until color clock 84
PF1 in use from color clock 84 up until 116
PF2 116 - 148
PF0 148 - 164
PF1 164 - 196
PF2 196 - 228

Action               | clocks | color | pixel |
---------------------+--------+-------+-------+
Set Background Color |   0    |   0   |   0   |
Set Playfield Color  |   10   |   30  |   0   |
Set PF0              |   15   |   45  |   0   |
Set PF1              |   20   |   60  |   0   |
Set PF2              |   25   |   75  |   7   |
NOP                  |   30   |   90  |  22   |
Set PF0              |   32   |   96  |  28   |
NOP                  |   37   |  111  |  43   |
Set PF1              |   39   |  117  |  49   |
NOP                  |   44   |  132  |  64   |
NOP                  |   46   |  138  |  70   |
NOP                  |   48   |  144  |  76   |
Set PF2              |   50   |  150  |  82   |
sta WSYNC            |   65   |  165  |  97   |


So for now, write a program that takes an input image, then:

a) converts to atari colors
b) then per-line:
  c) computes histogram of colors, sorted by frequency
  d) makes BG color most frequent
  e) makes PF color second most frequent
  f) analyzes each 4-pixel block. Compare error for BG color or PF color, pick
      minimum error
  g) constructs a time sequence of states for that line
  h) directly fills a program buffer with opcodes for that line
i) once finsihed with frame, should produce predicted output image and kernel
    text file, with header and footer so it can be assembled.

================================================================================

Kernel scheduling: do the states drive the schedule or does the schedule drive
the states?

In the end we want to produce opcodes. But there needs to be a more semantic way
to specify what is happening to the program. Like a domain-specific embedded
language that is eventually run through an optimizing compiler, that either
accepts or rejects the DSEL based on availability of resources.

Two levels of optimization - high-level DSEL is trying to minimize pixel error.
It can use any part of the TIA state machine at any time. Couple of different
approaches here worth exploring such as hand-coded heuristics like playfield
fitting, genetic algorithms, etc.

Fitting emits DSEL, which is just per-line state information: (class ScanLine):
colubk
playfield:
  80-bit bitfield, colupf
players - list of n elements, each containing:
  start_time - what pixel during scanout does this need to be triggered
  color
  bitmask
  nusiz - can be used to repeat player or scale player

Compilation then is a process of choosing the combination of state changes
required to get TIA in to that state by the time each piece is needed that
minimizes error for the picture. It's worth specifying entire state because it
may be possible to fit quite a bit. During fitting we will experiment with
throwing out different states that don't fit and examine resulting output
picture for minimum error.

--=<(* Fitting Heuristic A *)>=---

Take histogram of line. For each color C in histogram, sorted by most frequent
to least frequent:
  set background color to C
  playfield fitting
  player fitting
  if best error rate save as best fit

playfield fitting:
  for each 4-pixel block identify majority color if there is one. Break ties by
  identifying minimum-error color.
  histogram majority playfield colors. For now we adopt a single-color-per-line
  playfied color strategy. playfield color is most frequent non-background
  majority color. Then to determine bitfield we just compare error for 4 pixels
  at bg color vs 4 pixels at fg color.

player fitting:
  Identify bit patterns of uncovered colors, that is colors that aren't
  currently accurately covered by the BG or PF pattern. Maybe histogram each
  bit pattern (of oncovered pixels), starting with each pixel position, and try
  to identify commonality? This is an unsupervised learning clustering problem.
  http://en.wikipedia.org/wiki/Hamming_distance as well as color distance.

================================================================================

How to fit the refcheck image?
easy mode: 8 colors / line means 20 pixels / color. colubk/colupf thrashing:
turn pf on for 5 bits, then off for 5 bits, etc. While playfield is drawing bump
background color. While background is drawing bump playfield color.
colors are just 1-8
68 blank, 160 color

Action               | clocks | color | pixel | comment                        |
---------------------+--------+-------+-------+--------------------------------+
lda color1           |    0   |    0  |    0  | set bg to color1               |
sta colubk           |    2   |    6  |    0  |                                |
lda color2           |    5   |   15  |    0  | set pf to color2               |
sta colupf           |    7   |   21  |    0  |                                |
lda color3           |   10   |   30  |    0  | wait for bg to paint           |
nop                  |   13   |   39  |    0  |                                |
nop                  |   15   |   45  |    0  |                                |
nop                  |   17   |   51  |    0  |                                |
nop                  |   19   |   57  |    0  |                                |
nop                  |   21   |   63  |    0  | bg painting colu1 cc 68-88     |
nop                  |   22   |   72  |    0  |                                |
nop                  |   25   |   75  |    4  |                                |
nop                  |   27   |   81  |   13  |                                |
nop                  |   29   |   87  |   19  | pf painting colu2 cc 88-108    |
sta colubk           |   31   |   93  |   25  |                                |
lda color4           |   34   |  102  |   34  |                                |
sta colupf           |   36   |  108  |   40  | bg painting colu3 cc 108-128   |
lda color5           |   39   |  117  |   49  |                                |
nop                  |   41   |  123  |   55  | fg painting colu4 cc 128-148   |
sta colubk           |   43   |  129  |   61  |                                |
lda color6           |   46   |  138  |   70  |                                |
nop                  |   48   |  144  |   76  | bg painting colu5 cc 148-168   |
sta colupf           |   50   |  150  |   82  |                                |
lda color7           |   53   |  159  |   91  |                                |
nop                  |   55   |  165  |   97  | fg painting colu6 cc 168-188   |
sta colubk           |   57   |  171  |  103  |                                |
lda color8           |   60   |  180  |  112  |                                |
nop                  |   62   |  186  |  118  | bg painting colu7 cc 188-208   |
sta colupf           |   64   |  192  |  125  |                                |
sta WSYNC            |   67   |  201  |  134  |                                |

hblank:
  lda color1
  sta colubk
  lda color2
  sta colupf
scanout:
  ; bg is drawing for 20 pixels
  ; pf is drawing for 20 pixels
  lda color2
  sta colubk
  nop   ; bk starts during
  lda color

================================================================================

what would a genome program look like?

per-line genome is:
  a) initial conditions - what state did the previous line leave things in?
  b) up to 76 cycles of instructions. Can set X, Y, and A to constant values,
     or can store one of those three registers into any of the "fair game"
     zero-page TIA state registers such as COLUPF. Some strobes are also valid
     such as RESP0 and even VBLANK but not WSYNC. Invalid state modifications,
     like setting PF0 when it is being scanned out, or setting any color while
     it is being drawn, are treated as no-ops by the scheduler, which therefore
     modifies the clock count of that operation to 2 clocks. Do nothing is also
     a choice of action.
  c) an exit state.
  d) a predicted output scanline
  e) that ability to emit that line program in assembler

program generation:
  a) take image, break into ColuStrips
  b) initial image state is everything is 0
  c) for each ColuStrip:
    d) histogram colu values
    e) random seeding?
    f) generate kGenerationSize random programs (ScanLines)
      g) while cycle_count < 76 && error > kLineErrorTolerance:
        h) make weighted probability choice to do a load or a store.
        i) if load:
          j) pick register with uniform probability
          k) make weighted probability choice to pick colu or other
          l) if colu pick histogram-weighted colu or if other just random byte
        m) if store:
          n) pick register with uniform probability
          o) pick TIA address with uniform probability
        p) output StateChange looks like (load/store, register, value/address)
        q) supply StateChange to scheduler, along with current state.
        r) Scheduler will determine if StateChange is invalid, in which case it
           becomes a nop and takes 2 clocks. Otherwise it takes 3 or 4 clocks.
        s) Scheduler returns new state and ScanLine, assuming this state change
           was the last of the line.
    t) Run standard GA on lines. Save best candidate code & output. Can save in
       an image of stacked lines for each generation on each line. For scoring
       the programs we want a weighted sum of error and length. If error is
       below threshold we want to optimize for length more heavily perhaps.
  u) Winning program is the program for that line. For testing generate a kernel
     that paints a whole screen of that line, to ensure that our simulator is
     simulating lines correctly. Add the winning program to the list of
     ScanLines for the program and save output state as input for the next line.

to think about later:
  1) previous line packing. "what's the earliest I can set this?" ability to fit
     in some state changes well before scanline starts.
  2) bitfield random value seeding - are there other random values besides color
     histogram that might help seed better programs?
  3) redundant state changes become nops - did the porgram just set A and never
     did anything with it? that first set becomes a nop, freeing up a cycle.
  4) greedy generation algorithms - regenerate StateChange until we find one
     that decreases error, or regenerate ones that fail to schedule, etc
  5) output kernel could be upwards of 10K in size! Think about bankswitching
     strategies. They may impact timing on certain lines. Ultimately it may make
     the most sense in terms of timing to just let the program counter wrap and
     always be loading in fresh code behind the PC, since we never jump or fork
     or anything.


================================================================================

** wishlist

a) backfiller - as mentioned before, ability to move some state changes to
before scanline starts could be really invaluable. These other state changes
should be at a discount when it comes to calculating scanline cost. although
register/state dependency analysis seems interesting, a naive approach to this
feature might be to iterate through any available time slice in the past, try
to insert proposed instruction, and note if any pixels change color on the
output. Could have something like two methods "earliest time to load register"
which could look also for times when any register had been set to the required
value, if any, and "earliest time to load value," which would just look for
spots on the schedule to load the given tia address with the value. The two
parts of the function account well for different scenarios like strobing, where
nobody cares about the values they just need to be written, and setting multiple
addresses to same value, where once the register is loaded we can stuff away.

b) perception-weighted error metrics - seem to me vital in increasing quality of
fit, like CIEDE2000 for color distance. What about position in image weighting,
or edge vs. interior weighting? All pixels are _not_ created equal.

c) PNG lossless. Because TIFF.

d) Using the CIEDE2000 metric, do k-Means clustering or other unsupervised
learning algorithm to cluster colors in to n Atari colors. Then BG color strategy
just enumerates all atari colors to find minimum error. Playfield strategy does
same but enumerates all possible 2-color choices, 128 choose 2 = 128 * 127 =
16257 a computationally tractable number of choices to evaluate. Beyond that
we'll need to do heuristic clustering, 128 choose 3 = 2048256, which evaluating
1000 combos a second is a 34s eval (so maybe doable).

================================================================================

http://media.xiph.org/sintel/sintel-4k-png16/

Sintel images are 4096px x 1744px. (close to 2.39:1)  Assuming square pixels at
160x192 we would need to crop almost 2/3 of the horizontal image out, or down
to 1453x1744. If we can do 240 lines on an Atari, which it seems like we can
(max is 262 without interlacing), then we could go to 320x240, which is 4:3,
and just use 2 horizontal pixels for each of the 160 output pixels.

================================================================================

Upcoming changes:

a) stop quantizing to Atari colors on the input side. The question is then is it
useful to deprecate Frame? I think Frame is useful as an output vehicle, it is
handy to be able to just paint with bytes and not have to worry about their
representation outside of the Atari scope.

b) Kernel now accepts an Image not a Frame, and is trying to fit an Image. For
now we require the input image is 320x240.

c) PixelRow - is like ColuStrip but a row from an image. Can be arbitrary width.

d) Wouldn't be hard to change PaintInto() and Simulate() to work on Images and
PixelRows instead of Frames and ColuStrips - but this is the output side, so
let's just stick to Atari Colors.

e) Histogram now histos uint32s!.

f) BGColorStrategy now exhaustively computes minimum error color based on histo.

g) If we need to paint a frame at all we just double horizontal dimension.

================================================================================

Sintel Trailer at 480p - letterboxed 854x480 images. actual image is 854x364ish,
2.34:1, centered. sintel_trailer_2k_0334.png. 58 pixel border on top and bottom.

convert 480/sintel_trailer_2k_0334.png -crop 854x364+0+58 +repage cropped.tiff

Now we want to scale it down to 240 pixels tall, 563x240, so then crop 121.5
pixels off of each side :), or:

convert cropped.tiff -resize 563x240 resized.tiff
convert resized.tiff -crop 320x240+121+0 +repage final.tiff

Hrm, 240 lines seems a bit aggressive for Stella. Idea - we could try to emulate
video at 16:9, 320x180 rendered at 160x180, so after cropping scale to 422x180:

convert cropped.tiff -resize 422x180 resized.tiff

then crop to 320x180 by taking 51 off each side:

convert resized.tiff -crop 320x180+51+0 +repage final.tiff

================================================================================

OK playfield fitting is going (ish) next steps are:

a) Error maps input and output. These are grayscale images mapped to floats
which on input represent a multiplier on pixel error and on output represent a
per-pixel error distance.

b) scheduler? how to fit in new stuff

b) OpenCL CIEDE2000 error distance.

c) Per-file logging and per-file output

d) multi-threading per-file.

================================================================================

threading architecture

each kernel gets its own thread. OpenCL also has its own thread, but that one
has an event it blocks on so it must be terminated manually.

** Actually the "OpenCL has its own thread idea" kinda sucks.

use std::promise and std::future to communicate with OpenCL thread.

cl_events are associated with every command enqueue. cl_events can't be
associated with program builds but oh well. Command enqueues are to execute
kernels and to copy data in and out of the device.

within Kernel::Fit():
scoped_ptr<CLCommandQueue> queue_ = CLDeviceContext::MakeCommandQueue();

// Note: each kernel fitting thread should get its own command queue
// Somewhere in kernel thread we kick off a pallette compute based on a pixel
// strip.
std::future<std::unique_ptr<Pallette>> pallette = pixel_strip->BuildPallette(
    2, cl_command_queue_);


// Within PixelStrip::BuildPallette(size_t number_of_colors, CLCommandQueue queue):
// perhaps we've done this bit already, or perhaps we have an cl_image
// reference so PixelStrip already knows image and row data about itself
CLInputBuffer pixels_cl(<pointer to pixel data>, <size of pixel data>);
pixels_cl.EnqueueCopy(queue);

// pick the number of colors at random,
// there's some kind of global array of these (maybe Color:: has them?)
// in LAB space already.
CLOutputBuffer distances_cl(size_t)

std::unique_ptr<CLKernel> kernel = CLDeviceContext::MakeKernel("k_means");
kernel->SetArgument(uint32 index, size_t size, const void* arg);
""
""

kernel->Enqueue(queue);

std::future<std::unique_ptr<float[]>> future_distance = 
    distances_cl->EnqueueCopy(queue);

// .. enqueue all other work ..

// if you want, or can trust FIFO order of above enqueues and just wait on
// future_distance.
kernel->Wait();

// or whatever is correct syntax for this.
std::unique_ptr<float[]> distances = future_distance.get();

===============================================================================

the new (new (new)) plan:

a) install python colormath
b) take offical Atari RGB colors out of stella source code
c) write python script to take those official colors and generate the color
  tables in vcsmc, including an RGB color table as well as a Lab color table
  at D65.
d) python script also generates test data to test Lab CL shader against
  its calculated values
e) write testbed for lab CL shader that loads refcheck_image and validates
  values returned within epsilon.
f) back to work on k-means clustering algorithm:
  1) enqueue runs of lab shader on each row of input image
  2) then can discard input image and just keep rows
  3) those rows become the input for a given k-means run
g) profit! :)

===============================================================================

Want to increase complexity of approximate output. We need a few things:

a) A logging system. Will repay time investments in implementing with benefits
when it comes to debugging. Maybe?

b) A Scheduler object. Time to liberate ScanLines from the responsibility of
scheduling their own lines, and allow them to push state changes into prior
lines when appropriate.

c) Bank-switching strategy so single frames can fit in a ROM we can simulate.
(depends on Scheduler)

d) Linker to take binary blobs output by picc and wrap them into a .bin

e) Test rig to compare predicted output to simulated output screen captures.

===============================================================================

Scheduling. Strategies issue Constraints which is a State and a collection of
enums. For each varabiable in State there's an enum in Constraint which defines
DONT_CARE or REQUIRED. It also defines a deadline, a color_clock value that the
TIA must be in the state by. Provided to the scheduler (which can reject).

Scheduling works by examining each state variable in order and determining
which ones need to be changed. Determine earlieast list of availability for each
state change.

===============================================================================

Examine a single register value, such as PF0. Registers have many diverse
dependency rules. PF0 is used twice during each scanline but may otherwise be
set. COLUPF has a sort of depencency on the values in PF0-2 in that if any of
them have a pixel set to render then COLUPF is in use and must not be changed.
Registers are even more complicated - they are "in use" so long as the value
stored in them is still intended for another TIA address that has yet to be set.

Plan is to paint a line, and while painting that line update a color_clock time
constant for each part of the state machine that got used in the painting of
that line. Could keep a per-register list of Range objects defining periods
of color_clock time when these objects were in use. Could be called just like
PaintInto but..

Try working form input to output. Strategies will issue Constraints. Example
constraint for playfield-only fit:

at start of pixel out for that scanline, GP0 and GP1 are 0. COLUPF is xx.
COLUBK is yy. PF0 is zz. Rest are don't care.
16 color clocks later all of the above but now PF1 must be kk.
32 color clocks later all of the above but now PS2 must be ll.
etc. etc.

Perhaps we call these Specifications, or Specs. They are supplied to a Scheduler
which has a Kernel. The Scheduler can accept or reject a Spec. A Strategy can
bail on lines that don't fit in the scheduler, or suffer degraded service.

* Spec is one TIA state change and a deadline. They are accepted or rejected
individually by the scheduler.

===============================================================================

Back to requirements:

a) Redundant state change elimination. If a previous line has left something in
a desired state don't bother re-setting it.

b) Register packing - choose state changes earlier than can re-use register
values.

c) Back-scheduling - If possible, set a state change earlier, in a previous
scanline.

The first two seem easy if we are issuing individiual Specs. It is (c) that has
created the most confusion. Perhaps it's best to make a list of every state
variable and determine when it can be back-scheduled?

    VSYNC  = 0x00,  // vertical sync set-clear
    VBLANK = 0x01,  // vertical blank set-clear
    WSYNC  = 0x02,  // (strobe) wait for leading edge of horizontal blank
    RSYNC  = 0x03,  // (strobe) reset horizontal sync counter

- do not set for now.

    NUSIZ0 = 0x04,  // number-size player-missile 0
    NUSIZ1 = 0x05,  // number-size player-missile 1

- if associated player is zero, than these can be set anytime.
- if associated player is nonzero, depends on both old value and new value:
  * old value because the old code is assuming the player graphics will repeat
  on the set interval
  * new value because it should not kick in until desired output scanline.

    COLUP0 = 0x06,  // color-lum player 0
    COLUP1 = 0x07,  // colur-lum player 1

- if associated player is zero, than these can be set anytime.
- if associated player is non-zero, then these can be set as soon as last
  rendering of player color pixel is finished.

    COLUPF = 0x08,  // colur-lum playfield

- can be set after the last pixel on the previous scanline renders playfield
  color.

    COLUBK = 0x09,  // colur-lum background

- can be set after the last pixel on the previous scanline renders BG color.

    CTRLPF = 0x0a,  // control playfield ball size & collisions

- do not set.

    REFP0  = 0x0b,  // reflect player 0
    REFP1  = 0x0c,  // reflect player 1

- same rules as NUSIZ - can be set after last rendering of player bitfield
  on previous scanline, or whenever if player bitfield is 0.

    PF0    = 0x0d,  // playfield register byte 0
    PF1    = 0x0e,  // playfield register byte 1
    PF2    = 0x0f,  // playfield register byte 2

- very fixed, predicatble interval when these can be set. Can be set anytime
  after those times.

    RESP0  = 0x10,  // (strobe) reset player 0
    RESP1  = 0x11,  // (strobe) reset player 1
    RESM0  = 0x12,  // (strobe) reset missile 0
    RESM1  = 0x13,  // (strobe) reset missile 1
    RESBL  = 0x14,  // (strobe) reset ball

- not subject to back-scheduling at all.

    AUDC0  = 0x15,  // audio control 0
    AUDC1  = 0x16,  // audio control 1
    AUDF0  = 0x17,  // audio frequency 0
    AUDF1  = 0x18,  // audio frequency 1
    AUDV0  = 0x19,  // audio volume 0
    AUDV1  = 0x1a,  // audio volume 1

- not used by gfx scheduler.

    GRP0   = 0x1b,  // graphics player 0
    GRP1   = 0x1c,  // graphics player 1

- just like the nonzero scheduling of NUSIZ and REFP0, can be set after last
  expected rendering of player bitfield on previous scanline.

    ENAM0  = 0x1d,  // graphics (enable) missile 0
    ENAM1  = 0x1e,  // graphics (enable) missile 1
    ENABL  = 0x1f,  // graphics (enable) ball

- not considering for now, wait until after player graphics working.

    HMP0   = 0x20,  // horizontal motion player 0
    HMP1   = 0x21,  // horizontal motion player 1

- actually *have* to be set before the scanline, but can be set any time after
  the previous setting of HMOVE

    HMM0   = 0x22,  // horizontal motion missile 0
    HMM1   = 0x23,  // horizontal motion missile 1
    HMBL   = 0x24,  // horizontal motion ball

- leave alone for now.

    VDELP0 = 0x25,  // vertical delay player 0
    VDELP1 = 0x26,  // vertical delay player 1

- while potentially quite powerful probably best to ignore these for now.

    VDELBL = 0x27,  // vertical delay ball
    RESMP0 = 0x28,  // reset missile 0 to player 0
    RESMP1 = 0x29,  // reset missile 1 to player 1

- ignoring ball and missile for now so ignoring these too.

    HMOVE  = 0x2a,  // (strobe) apply horizontal motion

- has to be applied at the start of the hblank, so zero scheduling flexibiilty

    HMCLR  = 0x2b,  // (strobe) clear horizontal motion registers

- ???

    CXCLR  = 0x2c,  // (strobe) clear collision latches

- ignore.

so it seems that some things are depending on the last rendering of the relevant
bitfield, and some things the last rendering of the relevant color.

So when painting a scanline, would it be possible for State to update an MRU
table? Like kernel provides this MRU table to State::PaintInto().

There's another piece, which is the actual availabiliy of CPU cycles. Idea is to
introduce an "empty space" opcode which can be arbitrary length. NOP can
account for 2 cycles, and a rendundant STA can handle 3. But so empty space
opcode can only be at minimum 2 cycles long, or must be replaced by a LDA.
Or change from current list of opcodes to a more range-based schedules.

===============================================================================

Range object, maintains a pair of [start_color_clock, end_color_clock) times.
OpCodes can produce one if you give them a start time, can also give a duration
in color clocks. Could be stored interleaved, sort of like OpCodes and States:

range         range        range        range
      OpCode        OpCode       OpCode

but ranges can be zero and in fact should be because of good OpCode packing, so
why not have Ranges representing empty space and ranges representing 1 or more
OpCodes?

* TimeSpan object. Either BusyTimeSpan or IdleTimeSpan. Since it is not possible
to waste a single clock, and no instructions are only a single clock long, we
do not allow for TimeSpans to be 1 cpu clock/3 color cycles long. Our unit of
time is the color clock. A Schedule object contains a list of TimeSpans. It
starts with a single one that lasts the entire frame, from a few lines before
the start of the frame all the way to the end. Associated with each
BusyTimeSpan is a collection of OpCodes in order that are to be executed during
that time span. TimeSpans know about state, and so can provide not only input
and exit state transitions but can also paint into pixels and perform the update
logic currently performed by Scanline.

For OpCodes let's add a variable that tracks what row of output the scanline is
supporting. This may be useful in debugging, we can put the relevant row in the
comments in the asm output.

So now instead of competing ScanLines, it's competing Schedules. When starting
work on a new scan line we make a copy (could it be a weak copy?) of the
current schedule and this is provided to Strategy to modify. The schedule of the
winning strategy becomes the new schedule.

Need to add an "unknown" state to the State enum block.

* Change TimeSpan to Block. Block has a Range which indicates where it begins
and when it ends.

===============================================================================

debugging idea: fitter does everything as normal but on final ouput (conversion
to pixel_strip) we draw bg color as black, pf as gray, p0 as red, p1 as blue,
etc. to help visualize where we are using what graphics objects.

===============================================================================

// Quick check - is the spec already met?
// Finding a place for a spec.
// we look at the states going in to and out of blocks. Can only append
// instructions to existing blocks or create new blocks.

// Finding the earliest state we can mutate:
// Iterate backward through states starting with the last one, and stopping
// early if we encounter the start_time of the spec range:
// (a) state returns 0 - ask the state before it.
// (b) state returns kInfinity. Well shucks. Scheduling not supported. Treat
// as failure currently.
// (c) state returns n > 0. This is now the earliest state that we can add the
// spec to.

// Now we move forward in time, starting with the earliest state, and do the
// following:

// Attempt simple register packing. If any of the three registers have the
// value we want then we can re-use and skip the load. Otherwise we pick
// register based on LRU strategy (the State can keep track of this). In order
// to avoid invalidating register packing assumptions for future blocks we will
// want to ensure that register state goes back to unknown at the start of every
// block. From this we determine the number of clocks that the spec will take
// to insert.
// Given a clock count the question is if there's room or not.

// Thinking about Specs that can themselves be scheduled. Or some kind of
// Intermediate Representation here. Or OpCodes that have a time Range
// associated with them, or a weak ref back to a Spec, so they can be moved
// around a bit if needed..

// Examine block right after state, if it exists.
// if this block ends some time on or after n. Then we can attempt to append
// instructions to this block. If no block after state, or block ends too early,
// then we create a new block starting a minimum of 2 clock cycles from last
// block (for NOP insertion) and choose to append to that.

// OK now that we have our Block, can we schedule within it? Check register
// states, for now register packing is a simple question of if any of the 3
// registers coincidentally have the value we need then we can use it and skip
// the load. There may be a different design that allows for more intelligent
// register packing but we start with this. After determining the number of
// cycles we will need to add..

Repacking Problem:

State doesn't know what dependencies it has, only what values it has for
everything. So optimization becomes pretty tough as if input state changes in
a block this could impact costs. It shouldn't impact correctness if the code
in State::EarliestTimeAfter() is correct, in that states after the Spec being
scheduled have already given their consent to have this Spec scheduled before
them by returning 0. But it could impact speed, in that earlier decisions made
about cost of sets of Specs may actually be wrong now. For truly optimal code
the constraint solver would need to run on _all_ the relevant constraints at
once. But this makes the ability to answer quick questions like "which one of
these two sets of Specs is lower cost" much less tractable.

===============================================================================

Over-engineering FTW. Back to something I can implement. Scheduling specs.

From final state, moving backwards
  uint32 state_clock = EarliestTimeAfter(spec);

ROBOT SPEAK
I Dream of Wires

===============================================================================

Some thoughts on shceduling state changes before states that return 0 for
EarliestTimeAfter().

Returning 0 should mean that the called state is _invariant_ to the proposed
spec being scheduled before or not. Is this always the case? I can't think of
a single example where this doesn't hold currently. But possibilities for
other examples are interesting. Way you could check: Spec Sp is identified as
a candidate for scheduling before N states, which all returned 0. A new State
St is created and inserted. The N following states are then regenerated by
applying the associated OpCode transforms. Then as the check step you could go
back and ask each of the N' states and ask if they still return 0 for
EarliestTimeAfter(Sp).

On Scheduling. Block gets EarliestTimeAfter() too. It needs to ask each of its
states in reverse order EarliestTimeAfter(). If they all return 0 then Block
ETA can return 0. If any of them return a nonzero value than Block returns the
last state end_time() - 1, to indicate that the Spec could be appended to the
Block. If any return kInfinity then the Block returns kInfinity. Block can
append Specs, and can also give a cost estimate of appending a Spec.

===============================================================================

Another attempt at Scheduling. Idea is to move EarliestTimeAfter() out of State
and in to Schedule. This is to avoid the temptation on building EarliestTimeAfter
functions that depend on actual state values instead of the safer invariant stuff.
Like you can never set PF0 while it is being rendered, but can any other time
regardless of value. Otherwise it seems that you have to repack a Schedule every
time a Spec is scheduled before another one - which actually has to happen
(at least in part) anyway in the sense that once an OpCode has been laid down
the Schedule must regenerate State from that point forward. In any event for
first iteration Scheduling needs to be present State invariant and only depend
on timing.

EarliestTimeAfter changes to get a row_id, [0, kFrameHeightPixels), and a
deadline, conceptually similar to the old Range::end_time(). It is now a method
on Schedule instead of State. Blocks therefore also don't need to implement it,
and can become more pure container data structures, and might be worth
considering deprecation. But no. They are still doing register packing and seem
to represent a useful distinction between scheduled and unscheduled periods.
Also by tracking known/unknown register values, and assuming all register values
unknown at block entry, they allow us to schedule stuff before them without
breaking any register assumptions internally to that block.

How to schedule a Spec:

Pull row_id and deadline out from spec.range().end_time(). Call
eta = EarliestTimeAfter() on it. Iterate backwards through Blocks to find the
earliest block that begins before eta. If it ends before eta we start a new
Block, but new Block must be at least 2 cpu cycles from end of old block. Then,
moving through Blocks iteratively forward we either try to append to an existing
block if there's room or create a new Block. If we can do neither then the code
cannot Schedule that spec. After either finding an existing block to append to,
or creating a new Block, state must be re-propagated from that block forward.
or - since Scheduling is now invariant to State, perhaps we only need to
re-propagate state when simulating the scanline output, since we won't really
care about it until simulation? No, we need it, because of things like being
able to omit Specs if they are re-setting a value in the TIA that is already set.

Reversible scheduling is the other desirable thing - how to undo last N changes,
or lazy copy of Schedule for modification and then destruction. Perhaps an
internal Operation object, which is polymorphic and has two methods, like do()
and undo()? Then perhaps CostToAddSpec(s) could return a list of them with
associated total cost? So then actually adding them is just a matter of resupplying
the already-schedule stack of Operations to the Schedule. If we can manage
dependencies between stacks of Operations, so that they can all be undone in a
single call if needed (or never applied), then we also can support Strategies as
they will ultimately output a list of lists of Operations, each list dependent on
the previous list, and the Kernel can compare costs and qualities dependent on
each to make final determination.

OK, so Scheduler determines when the earliest time a Spec could happen. It can
then ask a given Schedule to produce a Change object which represents the
addition of that Spec to that Schedule. If the Schedule cannot accommodate the
Spec then it will not produce a Change.

===============================================================================

So looked at sound a little bit today and it seems like doing PCM is very
expensive on the CPU. I'm going to research that a bit further but it looks like
a Scheduler may be WAY overkill to manage what will really be just enough state
changes on a scanline to render an asymmetric playfield. Seriously!

The thinking goes that you set the audio sound control to just supply ones
and then you use the volume control to modulate that. You get 4 bits of volume
control so 4-bit PCM. The way to get any kind of audio quality is to of course
crank up the sample rate. 262 scanlines at 60 Hz means if you update once per
scanline you get 15720 Hz 4-bit PCM. So not so great. Twice gets you to 31440,
and three times per scanline gets you to 47160 Hz. The thing to do is to measure
perceived quality in the different sample rates. There are two audio circuits and
although they aren't actually in stereo (AFIAK) I could modulate each one to
represent a different audio channel, hopefully increasing audio fidelity at bit
as well. Each load/store is 5 clocks and 4 bytes of code. So at 15720 Hz we could
cram 120 ms of sound into 16K, which is just absolutely ridiculous! :)

Very high data rates. With updating playfield only on the screen, assuming
asymmetric playfield and new colors per line that's 6 state changes for the
playfield and 2 for the colors, 40 cycles, leaving 36 for audio updates, we can
try 3 stereo updates at 10 cycles per update (AUDV0 and AUDV1). Use DPC+ style
fast lookup of byte tables. 6 + 2 + 6 bytes is 14 bytes/scanline, approximate
as 16 bytes/scanline or 251520 bytes/second, 256 kBps or 2 Mbps.

===============================================================================

Going to use sox to try and encode some 4-bit samples of sample audio at the
different bitrates, just to get an initial approximation of what they might be
like.

sox in.wav -b 4 -c 1 --rate xxx out.wav (or out.raw)
-b 4 = 4 bit
-c 1 = mono
--rate = sample rate

split into two mono tracks:

sox sintel-master-st.flac sintel.left.wav remix 1
sox sintel-master-st.flac sintel.right.wav remix 2


resample to xxx Hz, drop to 8 bit, unsigned bytes, then switch nybbles (so that
high-order nybble shows up aligned to lower nybble of Atari AUDX registers)
and this file is ready to go:

sox in.wav --rate xxx -b 8 -e unsigned-integer -N out.raw

downmix to mono:
sox input.wav output.wav remix âˆ’

===============================================================================

TODO:

a) Move .cl files into compiled-in
b) Refactor cl tests into unit tests
c) Finish first cut of schedule.cc
d) Use asm to assemble output from picc into binary blob
e) Modify stella to support big blob binary

===============================================================================

The Spec binary format. Serialize Range to a pair of absolute time of color
clocks for origin of entire file. This means Range and Spec get an offset time
for serializing relative to. Little-endian format:

// 18 bytes/spec
//
// +--------+------------+------+--------+
// | type   | name       | size | offset |
// +--------+------------+------+--------+
// | uint64 | start_time |   8  |   0    |
// | uint64 | end_time   |   8  |   8    |
// | uint8  | TIA        |   1  |  16    |
// | uint8  | value      |   1  |  17    |
// +--------+------------+------+--------+

===============================================================================

picc redesign.

New job of picc is to output a Spec stream for each frame that was supplied to
the input, along with a frame rate. Aggressive picture fitting, add every thing
that can fit will be added to the output.

sndc/aucc Audio does the same.

Linker schedules frame necessities first (like turning on and off VBLANK), then
typically audio, then visual. Just greedy scheduler for now. Schedule every spec
and then drop the ones that don't fit. See how that works for now.

===============================================================================

Image Fitting.

First step processes colors into class categories. So input is 180 bytes of
minimum-error color classes. Start to build an output buffer of 180 bytes which
indicates what color class each of the output pixels will be. Fill with
background color class first. Then try each remaining color, counting the number
of pixels that would be filled by that playfield fit. Score is total number of
pixels that are rendered in the correct class. So playfield fit over BG color
fit alone may actually reduce the number of correctly fit pixels. Playfield
doesn't try to fit background color. Players do. P0 and P1 both try and fit all
colors, including the playfield color. One possibility is that, say for 4 color
fitting, that the best fit actually is using fewer colors than 4. Like P0 and P1
double up on a color, or help refine a Playfield fit by painting background
color over some misfit pixels. IF we arrive at a situation where the optimum fit
uses fewer colors than in the palette try to re-fit at the few color number
palette, then use the minimum total error of the two fits. If that happens again
we repeat until colors and shape are in agreement. Then take minimum total error
of those fits and call it a day.

Player Fitting. Needs to have an awareness of current player render state.
Strategies for moving player to the left are much easier, as we can just reset
the clock earlier with a strobe where we want the player to render. For moving
to the right either we can zero out the player graphics after it renders on
the previous scanline, then reset the player graphics and strobe?

===============================================================================

Shape Fitting.

For each color other than BG create an array of number of contiguous pixels
to the right:

OOOXXOOXOOOOXXXX000XXXXXXXXXO
00021001000043210009876543210

Playfield fitting is just look at groups of 4 pixels, 3 or 4 pixels is a 1, 0-2
pixels is a no.

Question - could we build a neural network or some other architecture amenable
to shape fitting work on the GPU using OpenCL?

Shape Histogramming:

Build bitfield where each bit represents a match to the color class in that
pixel position. 20 bytes total. Then histogram each of the 20 bytes. Q- is it
even possible to fire a sprite, using both players, to render 16 bytes of data
on a scan line? Seems very very tricky.

X0X0X
then time release of other player to fall in the first player's 0, so like:
X X X
 X X X  - this covers 6 * 8 or 48 pixels, so to cover will repeat 3 times + some:

X X X |X X X |X X X |X
 X X X |X X X |X X X |X

00000000001111111111222222222233333333334444444444555555555566666666667777777777
01234567890123456789012345678901234567890123456789012345678901234567890123456789
<-p0---><-p1---><-p0---><-p1---><-p0---><-p1---><-p0---><-p1---><-p0---><-p1--->
|-------||-------||-------||-------||-------||-------||-------||-------||-------|

00000000001111111111222222222233333333334444444444555555555566666666667777777777
01234567890123456789012345678901234567890123456789012345678901234567890123456789
<-p0--->        <-p0--->        <-p0--->
        <-p1--->        <-p1--->        <-p1--->
|-------||-------||-------||-------||-------||-------||-------||-------||-------|


ugh.

===============================================================================

Neural Network Player Shape Fitting:

Drawing order adds a "don't care" input, so -1 is something we can't draw
because it will clobber lower-priority color, 0 is "don't care" because it
will perhaps be clobbered by higher-priority color, and 1 is a draw in that
color.

There may be additional weighting on a given pixel for nonlinear color
difference reasons or possibly an additional error image map or some other
source.

Neural Nets get the previous input as an input too, because the cost of state
change is higher and will be evaluated in the output??

** NUSIZ networks - one for each input pixel, fanout 8 into 1 but 1 for each
possible grouping of 8, so the ith input neuron has pixels [i, i+7] as input.
This neuron is duplicated many times, meaning that the weights gained during
training are shared across all of the input layer.

<-- 80 pixels, one half of image -->
<-- 80ish input neurons, each seeing 8 continguous pixels -->
<-- hidden layer gets nonoverlapping groups of pixels, like first neuron gets
input neurons 0, 8, 16, 24, 32, 40, 48, 56,.. .80, second neuron gets 1, 9, 17,
25, 33, 41, etc.., so 8 groups of 10 neurons each, still 80 goddamn neurons -->
<--  8 neurons each taking the 10 inputs from above, shared weights -->
<-- output neuron taking 8 neurons, summing to one score -->

8 of the above networks, one for each value of NUSIZ, take the highest score.

** How to design player graphics values? - if you determine TIMING and NUSIZ
then perhaps the rest is just averaging the bits that will be rendered by the
output and going with 1 or zero in a practical way.

for i in [0, 7]:
<-- 80 pixels, one half of the image -->
<-- input neuron sees every ith pixel, so pixel 0, 8, 16, 24

===============================================================================

keyframe info extraction from ffmpeg:

ffprobe -show_frames -count_frames -select_streams v -print_format csv testVideo.mp4 > data.txt

also adjust ffmpeg to extract only encoded frames, not interpolated frames:

ffmpeg -i sintel-1024-stereo.ogv -vsync passthrough -pix_fmt rgba -f image2 -s 451x192 stills/frame-%7d.tiff

extract yuv format for fft work, format is YUV 4:2:0 uncompressed
(note size is rounded up to keep even-numbered, to avoid format depression)

ffmpeg -i sintel-1024-stereo.ogv -vsync passthrough -s 160x192 -pix_fmt yuv420p stills.yuv

creates one big blob file, which then needs slicing out to grayscale pngs:

xluma width height input_file.yuv stills_yuv/frame-%7d.png

Define a GrayMap object, can be 8 or 16 bits when saving to/reading from PNG
but is normally defined as a float.

===============================================================================

Saliency Map.

Read image in, unpack to zero-padded complex pairs in nearest power of two.
upload buffer to card.

Modify fft_radix_2 to support an input offset and output offset and stride.
fft on each row with input offset = output offset and output stride = 1, until
last round on each row where output offset and stride transpose matrix.
Then repeat fft and transpose again to get final 2d fft.

log remainder shader - takes the float2 blob, reads 9 values, takes their logs,
calculates the mean, subtracts the mean from the log, exponentiates result and
saves.

reverse FFT process, then send data back to main memory, extract real values
and save.


REFACTOR:

read image in, upload as blob of floats to card.
make first FFT buffer, run expand + zero fill shader which copies input data
and zero-fills into first FFT buffer.
forward FFT
spectral residual
inverse FFT
pack back into smaller image buffer, drop zero filling and imaginary part
square
can optionally pause here, copy back to main memory & save this image.
reduce to sum for mean
copy mean back to main memory
shader to threshold against value and save byte ff or 00 output.
copy bytemap back to main memory, save to bitmap file.

bitmaps allow for very compact bit-per-pixel representation.


command line to make side-by-side comparison of stills:

ffmpeg -pix_fmt abgr -s 160x192 -f image2 -i stills_yuv/frame-%02d.png -i \
stills_tsmap/frame-%02d.png -r 24 -filter_complex \
"[0:v:0]pad=iw*2:ih[bg]; [bg][1:v:0]overlay=w" oni_tsmap.mp4

===============================================================================

*** Player and Background fitting in this new era of Saliency Maps

The saliency maps provide a guideline as to the higher-value pixels in a given
image. Player fitting code should attempt to fit the areas highlighted by the
saliency map.

We can the image from top to bottom. We use the saliency map only to determine
the position and NUSIZ settings of the players. Players start with normal NUSIZ
and overlapping each other on the first scanline.

Start with the saliency map for the given scanline. Build an array of 152 bytes
each with a count of the number of saliency bits in this and the adjacent 7
pixels. The output is the array plus a flag indicating if there are any salient
bits on the line. The maxima are identified by location and sorted by pixel
count.

We need to decide where to move each player, if they are moving. Since moving
a player costs the loss of player graphics for the current scan line that is
the trade-off. So we analyze scan lines 2 at a time, current and next. current
already has coverage. The question is what maxima do we cover in next, and at
what cost to coverage in current? Score of each target is net gain in coverage.

so given a current line and a next line we evaluate each maxima in the next
line. For each maxima we produce two numbers, a net coverage score and an
expense metric (for tiebreakers). expense metric is some combo of distance
moved + some additional expense for NUSIZ. Then we sort these and choose
the highest coverage score with the lowest expense.

Some number 1-8 of adjacent pixels with ties. We keep
behind the top 2 classes - so perhaps there's an 8 loci but several 7 loci.
p1 should be considered only after p0 has done a fit and removed all matched
bits.

evaluation of maxima -
count the overlapped pixels gained by moving the player to this position.
count the pixels lost, if any, from current coverage by resetting the player
when moved.
consider a change to NUSIZ and if this would add any additional coverage,
count this coverage in.

** Dynamic Programming Solution

For each scanline identify *all* local maxima in adjacent salient pixels count
(there may be quite a few or only a few or none).
Handle each player at a time.

are these overlapping subproblems? They kind of feel like it, in the since that
once you've arrived at a point it doesn't matter how you got there it will
cost the same to travel to the next spot. But where you came from impacts how
you get there:

a b c d e f

g h i j k l

m n o p q r

Consider bottom-up approach? Like start at mnopqr and evaluate change in
coverage to move to each of ghijkl from each of last row. Then store max
coverage at each node along with max coverage direction, and iterate up.

Once at the top you have the best coverage table, to find max path through it
then start again at the bottom and take the best step at each point, recording
path through. Then reverse what's been recorded and that's the optimal path
through the saliency map.

Then, take a copy of the bitmap and wipe out all of the pixels covered by the
first player, then repeat the process for the second player.

===============================================================================

k-means hardware acceleration.

pick K colors at random, these are the K classes

for each input pixel choose minimum error class of the K classes - this is a
min over the K precomputed distances for each pixel - input is table of the
K colors along with error distance/color table, take min of K values in the
distance/color table and output the color for each pixel.

then for each classified input pixel choose minimum error color out of 128 -
k tables of 128 floats each, so for each pixel identify the current class and
add 128 error distances, one for each color, to that K table, then reduce table
to min errors and index.

TODO: rgb_to_lab needs to become a 2D kernel, so we can just convert entire
image to Lab once.

deprecate pixel_strip?

refactor the whole color distance code + downsample so that a whole pixel strip
is done in one call.

refactor K means to run on the GPU

===============================================================================

mean shift bg color fitting.
let's say 8 transitions per scan line, assuming each one takes 5 cpu cycles
for load/store. Can parameterize, perhaps crank up to 10 later.

* first rgb->lab, then run mean shift on image.
* for a given scanline:
  * compute distance from each atari color to each pixel
  * downsample errors to frame width - q: CIEDE2k distances are nonlinear, but
    Lab is supposed to be a roughly linear perceptual color space. Perhaps
    better to downsample image in Lab space first?
  * in any event, at the end we have an array of width x 128 colors of error
    distances, copy back from GPU. Might also be good to compute minimum error
    color at each pixel position and return that as well.

  * dynamic programming fitting:
  * error array is width * T transitions, coord x,y in error array means total
    error of switching at that pixel x for the yth transition. coord x,y in
    color array means minimum error color switched to at that pixel for
    transition.

  * to fill arrays: find minimum error color for pixel 0, store error in error
    array at 0,0 and store color value in color array at 0,0. Then for each
    pixel left in line add error distance, store cumulative total in i,0 error
    array and store same color in i,0 color array.
    for next line: there is some minimum distance D between transitions, so the
    first D pixels can have infinite error or same error and color as line
    above. On D,1 the error value is the error from D-1,0 plus the error from
    the minium-error color at that pixel

* reset:

alright, x pixels by y transitions. Error array at x,y is total error for
approximating _the rest of the line_ with the color stored at color array x,y.

useful input could be minimum-error color for each pixel if using that color
to approximate rest of line, as well as what that error might be.

* and again:

error array i,j has cumulative error for starting jth color transition at pixel
i, and color array i,j has the minimum-error color for starting at that pixel.

for first row of pixels at each position compute minimum error color to model
all previous pixels and that pixel as a given color and store minimum error and
color.

for subsequent rows j the assumption is that we will transition to a new color
at that pixel, instead of rendering that pixel (i) at the color in the row
above. Therefore the cumulative error is going to be the error at the i-1th
pixel on the j-1th row plus minimum color error to model this ith pixel and
the next K pixels. K is the minimum number of pixels we can remain on a color
before a transition, probably 9 since we cannot STA COLUBK any faster than 3
clock cycles. Or maybe 15 for the load/store pair, will decide later. Cumulative
error is just the cost of modeling that single pixel as that new color plus
the prior error at transition.


8 pixels of black (B) followed by 7 pixels of white (W), followed by 5 px of B:
B B B B B B B B W W W W W W W B B B B B
distances:
  B W
B 0 2
W 2 0

error matrix and color matrix, line-by-line:
0 0 0 0 0 0 0 0 2 4 6 8 a c e e e e e e
B B B B B B B B B B B B B B B B B B B B

0 0 0 0 0 0 0 0 0 2 4 6 8 a c e e e e e
B B B B B B B B W W W W W W W B B B B B

0 0 0 0 0 0 0 0 0 0 2 4 6 8 a c c c c c
B B B B B B B B W W W W W W W B B B B B

ah, we need a prior line transition point! like some documentation about what
choice we made on the prior line that lead to this optimal error situation.
the choice must be to our left, and a minimum of the transition pixel away to
our left.

ok, so at each subsequent position in the transition matrix we look at the
previous row for a minimum error and color, in the tie breakers we choose
?? minima. We then store that position in yet a third matrix, the prior
matrix p[i, j]. Cumulative error matrix has the sum of modeling previous
row as the required color + modeling that pixel as the new color.

  B W
B 1 2
W 2 1

error matrix, prior matrix (after first row) and color matrix:

   B  B  B  B  B  B  B  B  W  W  W  W  W  W  W  B  B  B  B  B

e: 1  2  3  4  5  6  7  8 10 12 14 16 18 20 22 23 24 25 26 27
c: B  B  B  B  B  B  B  B  B  B  B  B  B  B  B  B  B  B  B  B
p:  <-- first row, undefined

e: 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15
c: B  B  B  B  B  B  B  B  W  W  W  W  W  W  W
p: 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0

naw fuck it. Find minimum color error for each pixel, coalesce into adjacent
values, then issue specs for each line.
